{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_to_normalize = data.select_dtypes(include=['float64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate between objective and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = data.drop(columns=['HeartDisease'])\n",
    "obj = data['HeartDisease']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data between train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "char_train, char_test, obj_train, obj_test = train_test_split(char, obj, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [8], Accuracy: 0.70, Recall: 0.80, F1-Score: 0.73\n",
      "Selected Features: [8, 11], Accuracy: 0.74, Recall: 0.82, F1-Score: 0.77\n",
      "Selected Features: [8, 11, 7], Accuracy: 0.76, Recall: 0.83, F1-Score: 0.78\n",
      "Selected Features: [8, 11, 7, 3], Accuracy: 0.76, Recall: 0.83, F1-Score: 0.79\n",
      "Selected Features: [8, 11, 7, 3, 1], Accuracy: 0.77, Recall: 0.84, F1-Score: 0.79\n",
      "Selected Features: [8, 11, 7, 3, 1, 16], Accuracy: 0.77, Recall: 0.83, F1-Score: 0.79\n",
      "Selected Features: [8, 11, 7, 3, 1, 16, 18], Accuracy: 0.77, Recall: 0.82, F1-Score: 0.79\n",
      "Selected Features: [8, 11, 7, 3, 1, 16, 18, 6], Accuracy: 0.77, Recall: 0.83, F1-Score: 0.79\n",
      "Selected Features: [8, 11, 7, 3, 1, 16, 18, 6, 19], Accuracy: 0.77, Recall: 0.83, F1-Score: 0.79\n",
      "Selected Features: [8, 11, 7, 3, 1, 16, 18, 6, 19, 9], Accuracy: 0.76, Recall: 0.82, F1-Score: 0.78\n",
      "Selected Features: [8, 11, 7, 3, 1, 16, 18, 6, 19, 9, 2], Accuracy: 0.76, Recall: 0.82, F1-Score: 0.78\n",
      "Selected Features: [8, 11, 7, 3, 1, 16, 18, 6, 19, 9, 2, 17], Accuracy: 0.76, Recall: 0.82, F1-Score: 0.78\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "selected_features = []\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Evaluate the features chosen\n",
    "def evaluate_model(features):\n",
    "    rf_model.fit(char_train.iloc[:, features], obj_train)\n",
    "    predictions = rf_model.predict(char_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(obj_test, predictions)\n",
    "    recall = recall_score(obj_test, predictions)\n",
    "    f1 = f1_score(obj_test, predictions)\n",
    "    return accuracy, recall, f1\n",
    "\n",
    "# Bucle Forward Selection\n",
    "while len(selected_features) < char_train.shape[1]:\n",
    "    best_accuracy = 0\n",
    "    best_recall = 0\n",
    "    best_f1 = 0\n",
    "    best_feature = None\n",
    "    \n",
    "    # Iterate over the non-selected features\n",
    "    for feature_index in range(char_train.shape[1]):\n",
    "        if feature_index not in selected_features:\n",
    "            current_features = selected_features + [feature_index]\n",
    "            accuracy, recall, f1 = evaluate_model(current_features)\n",
    "            \n",
    "            # If the new accuracy is better than the last accuracy, updates it\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_recall = recall\n",
    "                best_f1 = f1\n",
    "                best_feature = feature_index\n",
    "    \n",
    "    # Adds the best feature to the other best ones\n",
    "    selected_features.append(best_feature)\n",
    "    \n",
    "    # Progress\n",
    "    print(f\"Selected Features: {selected_features}, Accuracy: {best_accuracy:.2f}, Recall: {best_recall:.2f}, F1-Score: {best_f1:.2f}\")\n",
    "\n",
    "print(\"Final Selected Features:\", selected_features)\n",
    "# Print the column names of the selected features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
